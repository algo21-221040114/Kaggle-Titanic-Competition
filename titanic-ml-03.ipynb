{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# reference: https://pytorch123.com/SecondSection/neural_networks/\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square you can only specify a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\nnet = Net()\nprint(net)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T09:13:57.385227Z","iopub.execute_input":"2022-12-09T09:13:57.385614Z","iopub.status.idle":"2022-12-09T09:13:59.462837Z","shell.execute_reply.started":"2022-12-09T09:13:57.385541Z","shell.execute_reply":"2022-12-09T09:13:59.461692Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss","metadata":{}},{"cell_type":"code","source":"params = list(net.parameters())\nprint(len(params))\nprint(params[6].size())  # conv1's .weight","metadata":{"execution":{"iopub.status.busy":"2022-12-09T09:18:20.565050Z","iopub.execute_input":"2022-12-09T09:18:20.565392Z","iopub.status.idle":"2022-12-09T09:18:20.571525Z","shell.execute_reply.started":"2022-12-09T09:18:20.565365Z","shell.execute_reply":"2022-12-09T09:18:20.570593Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"10\ntorch.Size([84, 120])\n","output_type":"stream"}]}]}