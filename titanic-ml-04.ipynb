{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport warnings\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\nimport pytorch_lightning as pl\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optimizer\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data \ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# Feature engineering\n## Proprecess data\ntrain['Sex'].replace('male', 0 ,inplace= True)\ntrain['Sex'].replace('female', 1 ,inplace= True)\ntrain['Relation'] = train['SibSp']+train['Parch']\ntrain['Ifhavekid'] = train['Parch']\ntrain['Ifhavekid'][train['Ifhavekid']>0] = 1\n\ndfresult = pd.DataFrame()\ndf = pd.get_dummies(train['Embarked'])\ndf.columns = ['Embarked_' +str(x) for x in df.columns ]\ntrain = pd.concat([train,df],axis = 1)\n\ntrain.Age = (train.Age-min(train.Age))/(max(train.Age)-min(train.Age))\ntrain.Fare = (train.Fare-min(train.Fare))/(max(train.Fare)-min(train.Fare))\n\ntest['Sex'].replace('male', 0 ,inplace= True)\ntest['Sex'].replace('female', 1 ,inplace= True)\ntest['Relation'] = test['SibSp']+test['Parch']\ntest['Ifhavekid'] = test['Parch']\ntest['Ifhavekid'][test['Ifhavekid']>0] = 1\n\ndfresult = pd.DataFrame()\ndf = pd.get_dummies(test['Embarked'])\ndf.columns = ['Embarked_' +str(x) for x in df.columns ]\ntest = pd.concat([test,df],axis = 1)\n\ntest.Age = (test.Age-min(test.Age))/(max(test.Age)-min(test.Age))\ntest.Fare = (test.Fare-min(test.Fare))/(max(test.Fare)-min(test.Fare))\n\nX = pd.concat([train['Pclass'],\n               train['Sex'], train['Age'], train['SibSp'], train['Parch'],  \n               train['Relation'], train['Fare']],axis=1)\nfor column in X:\n    if np.any(X[column].isnull()):\n        mean_val = np.mean(X[column])\n        X[column].fillna(mean_val, inplace=True)\n\ny = train['Survived']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 数据准备\nX = np.array(X)\ny = np.array(y)\ninput=torch.FloatTensor(X)\nlabel=torch.LongTensor(y)\n\n# create model\nclass Net(torch.nn.Module):\n    def __init__(self, n_output):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(7, 256, bias=False)\n        self.fc2 = nn.Linear(256, 128)  \n        self.fc3 = nn.Linear(128, 64)  \n        self.fc4 = nn.Linear(64, 16)  \n        self.out = nn.Linear(16,  n_output) \n\n    def forward(self, x):\n        x = torch.tanh(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = self.out(x)\n        return x\n\n# 定义优化器损失函数\nnet = Net(n_output=2)    #n_feature:输入的特征维度,n_hiddenb:神经元个数,n_output:输出的类别个数\noptimizer = torch.optim.SGD(net.parameters(), lr=0.05) # 优化器选用随机梯度下降方式\nloss_func = torch.nn.CrossEntropyLoss() # 对于多分类一般采用的交叉熵损失函数,","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 训练数据\ntrainloss = []\ntrainacc = []\nfor t in range(700):\n    out = net(input)                 # 输入input,输出out\n    loss = loss_func(out, label)     # 输出与label对比\n    \n    trainloss.append(loss.item())\n    \n    prediction = torch.max(out, 1)[1] # 返回index  0返回原值\n    pred_y = prediction.data.numpy()\n    target_y = label.data.numpy()\n    accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n    trainacc.append(accuracy)\n    \n    optimizer.zero_grad()   # 梯度清零\n    loss.backward()         # 前馈操作\n    optimizer.step()        # 使用梯度优化器","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 得出结果\nout = net(input) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\nout_prob = F.softmax(out)\nprint(type(out_prob))\nprint(out_prob)\nprediction = torch.max(out, 1)[1] # 返回index  0返回原值\npred_y = prediction.data.numpy()\ntarget_y = label.data.numpy()\n\n# 衡量准确率\naccuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\nprint(\"预测准确率\",accuracy)","metadata":{},"execution_count":null,"outputs":[]}]}