{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/arieswang98/titanic-ml-02?scriptVersionId=119126044\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport warnings\n\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nfrom matplotlib import pyplot as plt\nimport scikitplot as skplt\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\n\nimport pytorch_lightning as pl\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optimizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-14T02:36:57.779546Z","iopub.execute_input":"2023-02-14T02:36:57.781021Z","iopub.status.idle":"2023-02-14T02:37:09.482174Z","shell.execute_reply.started":"2023-02-14T02:36:57.780939Z","shell.execute_reply":"2023-02-14T02:37:09.480777Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Read data \ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# basic info\nprint('\\n'+'Some basic information about the train dataset'+'\\n')\ntrain.info()\n\nprint('\\n'+'Some basic information about the test dataset'+'\\n')\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2023-02-13T03:59:07.622059Z","iopub.execute_input":"2023-02-13T03:59:07.624645Z","iopub.status.idle":"2023-02-13T03:59:07.698465Z","shell.execute_reply.started":"2023-02-13T03:59:07.624589Z","shell.execute_reply":"2023-02-13T03:59:07.697606Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\nSome basic information about the train dataset\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\nSome basic information about the test dataset\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Feature engineering\n## Proprecess data\ntrain['Sex'].replace('male', 0 ,inplace= True)\ntrain['Sex'].replace('female', 1 ,inplace= True)\ntrain['Relation'] = train['SibSp']+train['Parch']\ntrain['Ifhavekid'] = train['Parch']\ntrain['Ifhavekid'][train['Ifhavekid']>0] = 1\n\ndfresult = pd.DataFrame()\ndf = pd.get_dummies(train['Embarked'])\ndf.columns = ['Embarked_' +str(x) for x in df.columns ]\ntrain = pd.concat([train,df],axis = 1)\n\ntrain.Age = (train.Age-min(train.Age))/(max(train.Age)-min(train.Age))\ntrain.Fare = (train.Fare-min(train.Fare))/(max(train.Fare)-min(train.Fare))\n\ntest['Sex'].replace('male', 0 ,inplace= True)\ntest['Sex'].replace('female', 1 ,inplace= True)\ntest['Relation'] = test['SibSp']+test['Parch']\ntest['Ifhavekid'] = test['Parch']\ntest['Ifhavekid'][test['Ifhavekid']>0] = 1\n\ndfresult = pd.DataFrame()\ndf = pd.get_dummies(test['Embarked'])\ndf.columns = ['Embarked_' +str(x) for x in df.columns ]\ntest = pd.concat([test,df],axis = 1)\n\ntest.Age = (test.Age-min(test.Age))/(max(test.Age)-min(test.Age))\ntest.Fare = (test.Fare-min(test.Fare))/(max(test.Fare)-min(test.Fare))","metadata":{"execution":{"iopub.status.busy":"2023-02-13T03:59:11.955106Z","iopub.execute_input":"2023-02-13T03:59:11.956269Z","iopub.status.idle":"2023-02-13T03:59:12.002441Z","shell.execute_reply.started":"2023-02-13T03:59:11.956203Z","shell.execute_reply":"2023-02-13T03:59:12.001535Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"}]},{"cell_type":"code","source":"X = pd.concat([train['Pclass'],\n               train['Sex'], train['Age'], train['SibSp'], train['Parch'],  \n               train['Relation'], train['Fare']],axis=1)\nfor column in X:\n    if np.any(X[column].isnull()):\n        mean_val = np.mean(X[column])\n        X[column].fillna(mean_val, inplace=True)\n\ny = train['Survived']","metadata":{"execution":{"iopub.status.busy":"2023-02-13T03:59:49.201155Z","iopub.execute_input":"2023-02-13T03:59:49.201669Z","iopub.status.idle":"2023-02-13T03:59:49.217716Z","shell.execute_reply.started":"2023-02-13T03:59:49.201632Z","shell.execute_reply":"2023-02-13T03:59:49.216343Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-13T03:59:53.820004Z","iopub.execute_input":"2023-02-13T03:59:53.820452Z","iopub.status.idle":"2023-02-13T03:59:53.866352Z","shell.execute_reply.started":"2023-02-13T03:59:53.820418Z","shell.execute_reply":"2023-02-13T03:59:53.86506Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"           Pclass         Sex         Age       SibSp       Parch    Relation  \\\ncount  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \nmean     2.308642    0.352413    0.367921    0.523008    0.381594    0.904602   \nstd      0.836071    0.477990    0.163383    1.102743    0.806057    1.613459   \nmin      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n25%      2.000000    0.000000    0.271174    0.000000    0.000000    0.000000   \n50%      3.000000    0.000000    0.367921    0.000000    0.000000    0.000000   \n75%      3.000000    1.000000    0.434531    1.000000    0.000000    1.000000   \nmax      3.000000    1.000000    1.000000    8.000000    6.000000   10.000000   \n\n             Fare  \ncount  891.000000  \nmean     0.062858  \nstd      0.096995  \nmin      0.000000  \n25%      0.015440  \n50%      0.028213  \n75%      0.060508  \nmax      1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Relation</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.308642</td>\n      <td>0.352413</td>\n      <td>0.367921</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>0.904602</td>\n      <td>0.062858</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.836071</td>\n      <td>0.477990</td>\n      <td>0.163383</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>1.613459</td>\n      <td>0.096995</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.271174</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.015440</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.367921</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.028213</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.434531</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.060508</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# reference：https://blog.csdn.net/yuekangwei/article/details/110310970\n# 定义BP神经网络\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom collections import Counter\nimport torch.nn.functional as Fun\n\n# 数据准备\nX = np.array(X)\ny = np.array(y)\ninput=torch.FloatTensor(X)\nlabel=torch.LongTensor(y)\n\n# 定义BP神经网络\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 定义隐藏层网络\n        self.out = torch.nn.Linear(n_hidden, n_output)   # 定义输出层网络\n\n    def forward(self, x):\n        x = Fun.relu(self.hidden(x))      # 隐藏层的激活函数\n        x = self.out(x)                   # 输出层不用激活函数\n        return x\n\n# 定义优化器损失函数\nnet = Net(n_feature=7, n_hidden=200, n_output=2)    #n_feature:输入的特征维度,n_hiddenb:神经元个数,n_output:输出的类别个数\noptimizer = torch.optim.SGD(net.parameters(), lr=0.07) # 优化器选用随机梯度下降方式\nloss_func = torch.nn.CrossEntropyLoss() # 对于多分类一般采用的交叉熵损失函数,","metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:02:48.409213Z","iopub.execute_input":"2023-02-09T09:02:48.409681Z","iopub.status.idle":"2023-02-09T09:02:48.430917Z","shell.execute_reply.started":"2023-02-09T09:02:48.409642Z","shell.execute_reply":"2023-02-09T09:02:48.429818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reference：https://blog.csdn.net/yuekangwei/article/details/110310970\n# network 2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# 数据准备\nX = np.array(X)\ny = np.array(y)\ninput=torch.FloatTensor(X)\nlabel=torch.LongTensor(y)\n\nclass Net(torch.nn.Module):\n    def __init__(self, n_output):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(7, 256, bias=False)\n        self.fc2 = nn.Linear(256, 128)  \n        self.fc3 = nn.Linear(128, 64)  \n        self.fc4 = nn.Linear(64, 16)  \n        self.out = nn.Linear(16,  n_output) \n\n    def forward(self, x):\n        x = torch.tanh(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = self.out(x)\n        return x\n\n# 定义优化器损失函数\nnet = Net(n_output=2)    #n_feature:输入的特征维度,n_hiddenb:神经元个数,n_output:输出的类别个数\noptimizer = torch.optim.SGD(net.parameters(), lr=0.05) # 优化器选用随机梯度下降方式\nloss_func = torch.nn.CrossEntropyLoss() # 对于多分类一般采用的交叉熵损失函数,","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 画出网络结构 \nMyConvNet = Net(n_output=2)\nprint(MyConvNet)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T04:54:03.645132Z","iopub.execute_input":"2023-02-13T04:54:03.645544Z","iopub.status.idle":"2023-02-13T04:54:03.653201Z","shell.execute_reply.started":"2023-02-13T04:54:03.645506Z","shell.execute_reply":"2023-02-13T04:54:03.652248Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Net(\n  (fc1): Linear(in_features=7, out_features=256, bias=False)\n  (fc2): Linear(in_features=256, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=64, bias=True)\n  (fc4): Linear(in_features=64, out_features=16, bias=True)\n  (out): Linear(in_features=16, out_features=2, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 训练数据\ntrainloss = []\ntrainacc = []\nfor t in range(700):\n    out = net(input)                 # 输入input,输出out\n    loss = loss_func(out, label)     # 输出与label对比\n    \n    trainloss.append(loss.item())\n    \n    prediction = torch.max(out, 1)[1] # 返回index  0返回原值\n    pred_y = prediction.data.numpy()\n    target_y = label.data.numpy()\n    accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n    trainacc.append(accuracy)\n    \n    optimizer.zero_grad()   # 梯度清零\n    loss.backward()         # 前馈操作\n    optimizer.step()        # 使用梯度优化器\n\n\n# 绘制训练过程\nplt.title('Train Loss')\nplt.plot(np.arange(len(trainloss)), trainloss)\nplt.legend(['Train Loss'], loc='upper right')\nplt.show()\n\nplt.title('Train Accuracy')\nplt.plot(np.arange(len(trainacc)), trainacc)\nplt.legend(['Train Accuracy'], loc='upper right')\nplt.show()\n\n# 得出结果\nout = net(input) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\nout_prob = F.softmax(out)\nprint(type(out_prob))\nprint(out_prob)\nprediction = torch.max(out, 1)[1] # 返回index  0返回原值\npred_y = prediction.data.numpy()\ntarget_y = label.data.numpy()\n\n# 衡量准确率\naccuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\nprint(\"预测准确率\",accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T07:44:43.027385Z","iopub.execute_input":"2023-02-10T07:44:43.027845Z","iopub.status.idle":"2023-02-10T07:44:47.137574Z","shell.execute_reply.started":"2023-02-10T07:44:43.027802Z","shell.execute_reply":"2023-02-10T07:44:47.136558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 混淆矩阵\nskplt.metrics.plot_confusion_matrix(target_y, pred_y, normalize=True) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-09T09:41:18.359122Z","iopub.execute_input":"2023-02-09T09:41:18.359637Z","iopub.status.idle":"2023-02-09T09:41:18.629474Z","shell.execute_reply.started":"2023-02-09T09:41:18.359599Z","shell.execute_reply":"2023-02-09T09:41:18.628091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC curve\npred_prob = out_prob.data.numpy()\nskplt.metrics.plot_roc(target_y, pred_prob)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T07:45:55.850101Z","iopub.execute_input":"2023-02-10T07:45:55.850614Z","iopub.status.idle":"2023-02-10T07:45:56.117841Z","shell.execute_reply.started":"2023-02-10T07:45:55.850576Z","shell.execute_reply":"2023-02-10T07:45:56.116289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Precision_recall Curve\nskplt.metrics.plot_precision_recall(target_y, pred_prob) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T07:49:59.13618Z","iopub.execute_input":"2023-02-10T07:49:59.136675Z","iopub.status.idle":"2023-02-10T07:49:59.38787Z","shell.execute_reply.started":"2023-02-10T07:49:59.136637Z","shell.execute_reply":"2023-02-10T07:49:59.386478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict\ndata_to_pred = pd.concat([test['Pclass'], test['Sex'], test['Age'], \n                          test['SibSp'], test['Parch'], test['Relation'], \n                          test['Fare']],axis=1)\nfor column in data_to_pred:\n    if np.any(data_to_pred[column].isnull()):\n        mean_val = np.mean(data_to_pred[column])\n        data_to_pred[column].fillna(mean_val, inplace=True)\n\ndata_to_pred = np.array(data_to_pred)\ninput = torch.FloatTensor(data_to_pred)\nout = net(input) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\nprediction = torch.max(out, 1)[1] # 返回index  0返回原值\npred_y = prediction.data.numpy()\n\nres = pd.concat([test['PassengerId'], pd.Series(pred_y)], axis=1)\nres.columns = ['PassengerId', 'Survived']\nres.to_csv('/kaggle/working/submission.csv', index=False)\nprint('over')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T09:57:52.193079Z","iopub.execute_input":"2022-12-09T09:57:52.193525Z","iopub.status.idle":"2022-12-09T09:57:52.214235Z","shell.execute_reply.started":"2022-12-09T09:57:52.193488Z","shell.execute_reply":"2022-12-09T09:57:52.212796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ninput = torch.randn(100, 3, 128, 128)\n\nclass Net(torch.nn.Module):\n    def __init__(self, n_output):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, out_channels=16, kernel_size=3, stride=2)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=(3, 2), stride=(2, 1))\n        \n        self.drop1 = nn.Dropout2d(p=0.2)\n        \n        self.conv2 = nn.Conv2d(16, out_channels=4, kernel_size=3, stride=2)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n        \n        self.conv3 = nn.Conv2d(4, out_channels=2, kernel_size=2, stride=1)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n        \n        self.fc1 = nn.Linear(648, 2)\n       \n        self.res = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool1(x)\n        x = torch.tanh(x)\n        x = self.drop1(x)\n        \n        x = self.conv2(x)\n        x = self.maxpool2(x)\n        x = F.relu(x)\n        \n        x = self.conv3(x)\n        x = self.maxpool3(x)\n        x = torch.sigmoid(x)\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.res(x)\n        \n        return x\n\n# 定义优化器损失函数\nnet = Net(n_output=2)    #n_feature:输入的特征维度,n_hiddenb:神经元个数,n_output:输出的类别个数\noptimizer = torch.optim.SGD(net.parameters(), lr=0.05) # 优化器选用随机梯度下降方式\nloss_func = torch.nn.CrossEntropyLoss() # 对于多分类一般采用的交叉熵损失函数,","metadata":{"execution":{"iopub.status.busy":"2023-02-14T04:34:09.72143Z","iopub.execute_input":"2023-02-14T04:34:09.722384Z","iopub.status.idle":"2023-02-14T04:34:09.779384Z","shell.execute_reply.started":"2023-02-14T04:34:09.722338Z","shell.execute_reply":"2023-02-14T04:34:09.777891Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# 画出网络结构 \nMyConvNet = Net(n_output=2)\nprint(MyConvNet)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T04:34:12.459396Z","iopub.execute_input":"2023-02-14T04:34:12.459815Z","iopub.status.idle":"2023-02-14T04:34:12.467301Z","shell.execute_reply.started":"2023-02-14T04:34:12.45978Z","shell.execute_reply":"2023-02-14T04:34:12.465942Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Net(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n  (maxpool1): MaxPool2d(kernel_size=(3, 2), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n  (drop1): Dropout2d(p=0.2, inplace=False)\n  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(2, 2))\n  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(4, 2, kernel_size=(2, 2), stride=(1, 1))\n  (maxpool3): MaxPool2d(kernel_size=(2, 2), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=648, out_features=2, bias=True)\n  (res): Softmax(dim=1)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"input = torch.randn(100, 3, 128, 128)\nprint(input.size()) \noutput = MyConvNet(input)\nprint(output.size())\nprint(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = nn.Softmax(dim=1)\ninput = torch.randn(2, 3)\noutput = m(input)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T04:33:12.602525Z","iopub.execute_input":"2023-02-14T04:33:12.602952Z","iopub.status.idle":"2023-02-14T04:33:12.612142Z","shell.execute_reply.started":"2023-02-14T04:33:12.602906Z","shell.execute_reply":"2023-02-14T04:33:12.611162Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"tensor([[0.2954, 0.3520, 0.3526],\n        [0.1483, 0.7538, 0.0979]])\n","output_type":"stream"}]}]}