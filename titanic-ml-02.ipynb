{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/arieswang98/titanic-ml-02?scriptVersionId=113172895\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport warnings\n\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nfrom matplotlib import pyplot as plt\nimport scikitplot as skplt\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\n\nimport pytorch_lightning as pl\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optimizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-07T07:11:27.487644Z","iopub.execute_input":"2022-12-07T07:11:27.488087Z","iopub.status.idle":"2022-12-07T07:11:38.837946Z","shell.execute_reply.started":"2022-12-07T07:11:27.487995Z","shell.execute_reply":"2022-12-07T07:11:38.836356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data \ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# basic info\nprint('\\n'+'Some basic information about the train dataset'+'\\n')\ntrain.info()\n\nprint('\\n'+'Some basic information about the test dataset'+'\\n')\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:11:44.708604Z","iopub.execute_input":"2022-12-07T07:11:44.709606Z","iopub.status.idle":"2022-12-07T07:11:44.77287Z","shell.execute_reply.started":"2022-12-07T07:11:44.709566Z","shell.execute_reply":"2022-12-07T07:11:44.771564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\n## Proprecess data\ntrain['Sex'].replace('male', 0 ,inplace= True)\ntrain['Sex'].replace('female', 1 ,inplace= True)\ntrain['Relation'] = train['SibSp']+train['Parch']\ntrain['Ifhavekid'] = train['Parch']\ntrain['Ifhavekid'][train['Ifhavekid']>0] = 1\n\ndfresult = pd.DataFrame()\ndf = pd.get_dummies(train['Embarked'])\ndf.columns = ['Embarked_' +str(x) for x in df.columns ]\ntrain = pd.concat([train,df],axis = 1)\n\ntrain.Age = (train.Age-min(train.Age))/(max(train.Age)-min(train.Age))\ntrain.Fare = (train.Fare-min(train.Fare))/(max(train.Fare)-min(train.Fare))\n\ntest['Sex'].replace('male', 0 ,inplace= True)\ntest['Sex'].replace('female', 1 ,inplace= True)\ntest['Relation'] = test['SibSp']+test['Parch']\ntest['Ifhavekid'] = test['Parch']\ntest['Ifhavekid'][test['Ifhavekid']>0] = 1\n\ndfresult = pd.DataFrame()\ndf = pd.get_dummies(test['Embarked'])\ndf.columns = ['Embarked_' +str(x) for x in df.columns ]\ntest = pd.concat([test,df],axis = 1)\n\ntest.Age = (test.Age-min(test.Age))/(max(test.Age)-min(test.Age))\ntest.Fare = (test.Fare-min(test.Fare))/(max(test.Fare)-min(test.Fare))","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:12:11.523101Z","iopub.execute_input":"2022-12-07T07:12:11.523478Z","iopub.status.idle":"2022-12-07T07:12:11.556966Z","shell.execute_reply.started":"2022-12-07T07:12:11.523436Z","shell.execute_reply":"2022-12-07T07:12:11.555416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([train['Pclass'],\n               train['Sex'], train['Age'], train['SibSp'], train['Parch'],  \n               train['Relation'], train['Fare']],axis=1)\nfor column in X:\n    if np.any(X[column].isnull()):\n        mean_val = np.mean(X[column])\n        X[column].fillna(mean_val, inplace=True)\n\ny = train['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:15:29.460418Z","iopub.execute_input":"2022-12-07T07:15:29.460811Z","iopub.status.idle":"2022-12-07T07:15:29.471684Z","shell.execute_reply.started":"2022-12-07T07:15:29.460778Z","shell.execute_reply":"2022-12-07T07:15:29.470447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:15:40.927086Z","iopub.execute_input":"2022-12-07T07:15:40.92745Z","iopub.status.idle":"2022-12-07T07:15:40.971381Z","shell.execute_reply.started":"2022-12-07T07:15:40.927421Z","shell.execute_reply":"2022-12-07T07:15:40.970153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reference：https://blog.csdn.net/yuekangwei/article/details/110310970\n\nimport numpy as np\nimport torch\nfrom collections import Counter\nfrom sklearn import datasets\nimport torch.nn.functional as Fun\n\n# 数据准备\nX = np.array(X)\ny = np.array(y)\ninput=torch.FloatTensor(X)\nlabel=torch.LongTensor(y)\n\n# 定义BP神经网络\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 定义隐藏层网络\n        self.out = torch.nn.Linear(n_hidden, n_output)   # 定义输出层网络\n\n    def forward(self, x):\n        x = Fun.relu(self.hidden(x))      # 隐藏层的激活函数\n        x = self.out(x)                   # 输出层不用激活函数\n        return x\n\n# 定义优化器损失函数\nnet = Net(n_feature=7, n_hidden=200, n_output=2)    #n_feature:输入的特征维度,n_hiddenb:神经元个数,n_output:输出的类别个数\noptimizer = torch.optim.SGD(net.parameters(), lr=0.07) # 优化器选用随机梯度下降方式\nloss_func = torch.nn.CrossEntropyLoss() # 对于多分类一般采用的交叉熵损失函数,\n\n\n# 训练数据\ntrainloss = []\ntrainacc = []\nfor t in range(200):\n    out = net(input)                 # 输入input,输出out\n    loss = loss_func(out, label)     # 输出与label对比\n    \n    trainloss.append(loss.item())\n    \n    prediction = torch.max(out, 1)[1] # 返回index  0返回原值\n    pred_y = prediction.data.numpy()\n    target_y = label.data.numpy()\n    accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n    trainacc.append(accuracy)\n    \n    optimizer.zero_grad()   # 梯度清零\n    loss.backward()         # 前馈操作\n    optimizer.step()        # 使用梯度优化器\n\n\n# 绘制训练过程\nplt.title('Train Loss')\nplt.plot(np.arange(len(trainloss)), trainloss)\nplt.legend(['Train Loss'], loc='upper right')\nplt.show()\n\nplt.title('Train Accuracy')\nplt.plot(np.arange(len(trainacc)), trainacc)\nplt.legend(['Train Accuracy'], loc='upper right')\nplt.show()\n\n# 得出结果\nout = net(input) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\nprediction = torch.max(out, 1)[1] # 返回index  0返回原值\npred_y = prediction.data.numpy()\ntarget_y = label.data.numpy()\n\n# 衡量准确率\naccuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\nprint(\"预测准确率\",accuracy)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-07T08:37:07.439853Z","iopub.execute_input":"2022-12-07T08:37:07.440596Z","iopub.status.idle":"2022-12-07T08:37:08.044089Z","shell.execute_reply.started":"2022-12-07T08:37:07.440552Z","shell.execute_reply":"2022-12-07T08:37:08.042679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict\ndata_to_pred = pd.concat([test['Pclass'], test['Sex'], test['Age'], \n                          test['SibSp'], test['Parch'], test['Relation'], \n                          test['Fare']],axis=1)\nfor column in data_to_pred:\n    if np.any(data_to_pred[column].isnull()):\n        mean_val = np.mean(data_to_pred[column])\n        data_to_pred[column].fillna(mean_val, inplace=True)\n\ndata_to_pred = np.array(data_to_pred)\ninput = torch.FloatTensor(data_to_pred)\nout = net(input) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\nprediction = torch.max(out, 1)[1] # 返回index  0返回原值\npred_y = prediction.data.numpy()\n\nres = pd.concat([test['PassengerId'], pd.Series(pred_y)], axis=1)\nres.columns = ['PassengerId', 'Survived']\nres.to_csv('/kaggle/working/submission.csv', index=False)\nprint('over')","metadata":{"execution":{"iopub.status.busy":"2022-12-07T08:45:40.032181Z","iopub.execute_input":"2022-12-07T08:45:40.032556Z","iopub.status.idle":"2022-12-07T08:45:40.05653Z","shell.execute_reply.started":"2022-12-07T08:45:40.032525Z","shell.execute_reply":"2022-12-07T08:45:40.054849Z"},"trusted":true},"execution_count":null,"outputs":[]}]}